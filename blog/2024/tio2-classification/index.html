<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Training a neural network for the classification of TiO2 XRD patterns | Jan Schützke</title> <meta name="author" content="Jan Schützke"> <meta name="description" content="A guide to instruct and demonstrate how neural networks can be employed for automatic phase identification in powder XRD patterns."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jschuetzke.github.io/blog/2024/tio2-classification/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jan </span>Schützke</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/showroom/">showroom</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">work</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/repositories/">repositories</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Training a neural network for the classification of TiO2 XRD patterns</h1> <p class="post-meta">February 26, 2024</p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/python"> <i class="fa-solid fa-hashtag fa-sm"></i> python</a>   <a href="/blog/tag/xrd"> <i class="fa-solid fa-hashtag fa-sm"></i> xrd</a>   <a href="/blog/tag/classification"> <i class="fa-solid fa-hashtag fa-sm"></i> classification</a>     ·   <a href="/blog/category/guides"> <i class="fa-solid fa-tag fa-sm"></i> guides</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>This post demonstrates the usage of neural networks for automatic analysis of powder XRD data. In this application, the objective is to identify various TiO<sub>2</sub> structures based on their characteristic pattern.</p> <h2 id="titanium-oxides">Titanium Oxides</h2> <p>Titanium oxide TiO<sub>2</sub> can crystallize in various arrangements, depending on diverse influences. According to crystalline databases, such as the <a href="https://www.crystallography.net/cod/" rel="external nofollow noopener" target="_blank">COD</a> or the <a href="https://icsd.fiz-karlsruhe.de/" rel="external nofollow noopener" target="_blank">ICSD</a>, there are 5 major phases to consider at ambient conditions:</p> <ul> <li>Anatase, e.g., COD 9009086</li> <li>Rutile, e.g., COD 9015662</li> <li>Brookite, e.g., COD 8104269</li> <li>β-TiO<sub>2</sub>, e.g., COD 1528778</li> <li>TiO<sub>2</sub>-II, e.g., COD 1530026</li> </ul> <p>While the chemical composition for all of these phases is identical, their crystalline structures differ. Therefore, the XRD technique is a useful method to determine the exact phase for titanium oxide samples.</p> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/xrd-class-patterns-480.webp 480w, /assets/img/xrd-class-patterns-800.webp 800w, /assets/img/xrd-class-patterns-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/xrd-class-patterns.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>The above figure shows the simulated, ideal diffraction patterns for the different structures. While the highest peak lies in the range between 25 and 30 degrees \(2θ\) for 4 of the 5 variants (TiO<sub>2</sub>-II being the exception), the structures are distinguishable based on the presence and positions of additional diffraction peaks. Therefore, it can be expected that an automated classification algorithm is able to classify the structures accordingly.</p> <h2 id="network-training">Network Training</h2> <p>The use of neural networks for analysis of powder XRD patterns has been demonstrated in various publications.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup><sup>,</sup><sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> Nonetheless, exemplary data is necessary to train the network models. This data should demonstrate all types of variations found in the powder XRD patterns, so the model can learn robust classification rules for the different structures. However, measured XRD patterns are not readily available for all types of materials. Thus, simulated XRD patterns are typically utilized as training data. The previous <a href="https://jschuetzke.github.io/blog/2024/realistic-xrd-simulation/">blog post</a> explains the procedure in detail using the <em>python-powder-diffraction</em> package.</p> <h3 id="requirements">Requirements</h3> <ol> <li>A fresh Python environment, e.g., through venv or conda.</li> <li>CIFs for the different TiO<sub>2</sub> variants, e.g., from the COD.</li> <li>The <a href="https://github.com/jschuetzke/python-powder-diffraction/" rel="external nofollow noopener" target="_blank"><em>python-powder-diffraction</em></a> package installed in the environment.</li> <li>A deep learning package, such as <a href="https://tensorflow.org/" rel="external nofollow noopener" target="_blank"><em>TensorFlow</em></a> or <a href="https://pytorch.org/" rel="external nofollow noopener" target="_blank"><em>PyTorch</em></a> installed in the environment.</li> </ol> <h3 id="data-generation">Data Generation</h3> <p>The <em>python-powder-diffraction</em> provides several methods to generate varied patterns for each structure, but the fastest option is the use of the <code class="language-plaintext highlighter-rouge">generate-varied-patterns</code> script provided in the package. Simply place all CIFs in a folder (e.g., in a directory called <em>phases</em>), activate the enviroment and use <code class="language-plaintext highlighter-rouge">generate-varied-patterns phases</code> to generate the signals.</p> <p>Furthermore, there are several arguments to modify the data generation procedure. Here, we’re aiming to simulate patterns in the 5 to 90 degrees \(2θ\) range with step width \(0.01^\circ \Delta 2\theta\). To depict the peak positions, intensities, and shape variations, we also specify values for those parameters:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>generate-varied-patterns phases --theta_range "(5,90)" --strain 0.04 --texture 0.8 --domain_sizes "(20,50)" --n_train 100 --n_val 20
</code></pre></div></div> <p>Executing this script generates four numpy files in the <em>phases</em> directory: <code class="language-plaintext highlighter-rouge">x_train.npy</code>, <code class="language-plaintext highlighter-rouge">x_val.npy</code>, <code class="language-plaintext highlighter-rouge">y_train.npy</code>, and <code class="language-plaintext highlighter-rouge">y_val.npy</code>. The <em>x</em> arrays contain the signals (100 or 20 variants for each CIF) and the <em>y</em> arrays the labels for each pattern. By default, the CIFs are sorted according to their name and given an identifier in ascending order. Therefore, the labels file only contains the numerical identifier that specifies the structure for each signal in the <em>train</em> and <em>val</em> files.</p> <p>Furthermore, the artificial signals should also contain background and noise. This can be added using the <code class="language-plaintext highlighter-rouge">add-noise</code> script. Noise can either be added to each signals array separately or in a single script execution using the <code class="language-plaintext highlighter-rouge">--template</code> argument. To add noise in a single call, we change the directory to the <em>phases</em> folder and call the script as follows:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>add-noise --template "x_" --noise_min 0.01 --noise_max 0.05
</code></pre></div></div> <p>This call adds random background and noise to the <code class="language-plaintext highlighter-rouge">x_train.npy</code> and <code class="language-plaintext highlighter-rouge">x_val.npy</code> files and saves the modified arrays as <code class="language-plaintext highlighter-rouge">x_train_noise.npy</code> and <code class="language-plaintext highlighter-rouge">x_val_noise.npy</code>. The resulting signals appear as follows:</p> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/xrd-class-signals-480.webp 480w, /assets/img/xrd-class-signals-800.webp 800w, /assets/img/xrd-class-signals-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/xrd-class-signals.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="neural-network">Neural Network</h3> <p>Convolutional neural networks employ various filters that are shifted across the input to identify features in the signals. Therefore, this architecture is well suited to distinguish the relevant peak-encoded information from background and noise. Here, we use a simple network consisting of three convolutional layers. Each generated signal corresponds to one of the unique structures, which represents a multi-class task. Therefore, the output of the network has five neurons and the outputs are scaled using the <em>softmax</em> activation function, to represent the predicted values as a probability distribution.</p> <p>The neural network model, in this example using the keras implementation with a tensorflow backend, can be defined as follows:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">metrics</span>

<span class="k">def</span> <span class="nf">get_cnn</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">8501</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">input_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
                               <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">input</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span>
                      <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">input_layer</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">MaxPool1D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span>
                      <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">MaxPool1D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span>
                      <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">MaxPool1D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">flat</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="sh">"</span><span class="s">adam</span><span class="sh">"</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">sparse_categorical_crossentropy</span><span class="sh">'</span><span class="p">,</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">metrics</span><span class="p">.</span><span class="nc">SparseCategoricalAccuracy</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></div> <p>This implements a model with 8501 input neurons and 5 neurons in the output layer. Three convolutional layers with 16 filters each (and kernel sizes 35, 25, and 15) are employed within the network, together with pooling operations to reduce the dimensionality of the signals. The label files <code class="language-plaintext highlighter-rouge">y_train.npy</code> and <code class="language-plaintext highlighter-rouge">y_val.npy</code> specify the identifiers of each class, so the <em>sparse_categorical_crossentropy</em> loss (and accuracy object) is used. Furthermore, the <em>Adam</em> optimizer is used during model training.</p> <h3 id="training-procedure">Training Procedure</h3> <p>The next step involves the training of the neural network using the simulated patterns. Therefore, the first steps of the training script involve loading the signals.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">tensorflow.keras</span> <span class="kn">import</span> <span class="n">callbacks</span>
<span class="kn">from</span> <span class="n">powdiffrac.processing</span> <span class="kn">import</span> <span class="n">scale_min_max</span>
<span class="kn">from</span> <span class="n">model</span> <span class="kn">import</span> <span class="n">get_cnn</span>


<span class="n">xt</span> <span class="o">=</span> <span class="nf">scale_min_max</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">./phases/x_train.npy</span><span class="sh">"</span><span class="p">))</span>
<span class="n">xv</span> <span class="o">=</span> <span class="nf">scale_min_max</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">./phases/x_val.npy</span><span class="sh">"</span><span class="p">))</span>
<span class="n">yt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">./phases/y_train.npy</span><span class="sh">"</span><span class="p">)</span>
<span class="n">yv</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">./phases/y_val.npy</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>Following this, the model can get initiliazed based on the properties of the training data. Consisting of 5 unique classes, adapting the model to the training data requires only few epochs.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="nf">get_cnn</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">xv</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">classes</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">yv</span><span class="p">).</span><span class="n">size</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">xv</span><span class="p">,</span> <span class="n">yv</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">./phases/model.keras</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>In my configuration (GTX 1070), the model achieves 100% accuracy on training and validation set. This is especially remarkable because the model has never seen the varied patterns in the validation data.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 10/10
16/16 - 0s - loss: 1.3780e-07 - accuracy: 1.0000 - val_loss: 4.3869e-07 - val_accuracy: 1.0000 - 209ms/epoch - 13ms/step
</code></pre></div></div> <h2 id="network-application">Network Application</h2> <p>While the model has been trained and evaluated on simulated patterns, it is also readily applicable for the classification of measured powder XRD patterns. Therefore, the following section demonstrates the performance of the neural network model on measured signals.</p> <h3 id="rruff-measurements">RRUFF Measurements</h3> <p>The <a href="https://rruff.info" rel="external nofollow noopener" target="_blank">RRUFF</a> database provides measured XRD patterns and Raman spectra for various materials. This database includes entries for some of the TiO<sub>2</sub> variants, enabling an effective evaluation of the trained neural network model using measured signals. The database includes the following entries:</p> <table> <thead> <tr> <th>Phase</th> <th style="text-align: right">Entries</th> <th style="text-align: right">…</th> <th style="text-align: right">…</th> <th style="text-align: right">…</th> </tr> </thead> <tbody> <tr> <td>Anatase</td> <td style="text-align: right">R060277</td> <td style="text-align: right">R070582</td> <td style="text-align: right">R120013</td> <td style="text-align: right">R120064</td> </tr> <tr> <td>Rutile</td> <td style="text-align: right">R040049</td> <td style="text-align: right">R050031</td> <td style="text-align: right">R050417</td> <td style="text-align: right">R060493</td> </tr> <tr> <td>Brookite</td> <td style="text-align: right">R050363</td> <td style="text-align: right">R050591</td> <td style="text-align: right">R130225</td> <td style="text-align: right"> </td> </tr> </tbody> </table> <p>Unfortunately, the entries for the four Anatase samples do not contain measured XRD patterns and the database only provides simulated signals. Nonetheless, the process to generate those simulated patterns presumably differs from the approach to generate the training signals, so this is another useful tool to test the robustness of the automated analysis approach.</p> <h3 id="prediction">Prediction</h3> <p>The measured patterns are available for download from the RRUFF, enabling the evaluation of the trained model in a Python script. Accordingly, the scans are imported into Python (using numpy functions) and Min-Max-scaled prior to feeding the signals into the network. The order of the signals corresponds to the table above, meaning that signals 1-4 represent anatase, signals 5-8 represent rutile, and the remaining depict brookite.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="sh">"</span><span class="s">./phases/model.keras</span><span class="sh">"</span><span class="p">)</span>
<span class="n">anatase_1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="sh">'</span><span class="s">./meas/Anatase__R060277-9__Powder__Xray_Data_XY_RAW__5487.txt</span><span class="sh">'</span><span class="p">,</span> <span class="n">comments</span><span class="o">=</span><span class="sh">'</span><span class="s">#</span><span class="sh">'</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="p">)</span>
<span class="bp">...</span>
<span class="n">meas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="mi">11</span><span class="p">,</span><span class="mi">8501</span><span class="p">])</span>
<span class="n">meas</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">interp</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mf">5.</span><span class="p">,</span><span class="mf">90.</span><span class="p">,</span><span class="mi">8501</span><span class="p">),</span> <span class="n">anatase_1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">anatase_1</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="bp">...</span>
<span class="n">meas</span> <span class="o">=</span> <span class="nf">scale_min_max</span><span class="p">(</span><span class="n">meas</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">meas</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 2])
</code></pre></div></div> <p>The network provides the correct predictions for the measured signals (identifiers-&gt; 1: Anatase, 2: β-TiO<sub>2</sub>, 2: Brookite, 3: Rutile, 4: TiO<sub>2</sub>-II), corresponding to an accuracy score of 100%.</p> <h3 id="limitations">Limitations</h3> <p>While the network demonstrates proficiency in classifying XRD patterns of titanium oxide samples, there are several other cases that can occur when analyzing a crystalline sample. For once, the sample could contain several phases, such as impurities. Secondly, the sample could contain neither of the defined phases. The network presented here is not trained to handle either of these exceptional cases. Accordingly, the network classified the first rutile sample from the RRUFF (R040049) as rutile, despite the presence of hematite in the sample (as indicated in the RRUFF entry). Due to the use of the <em>softmax</em> activation function in the final layer, the output with the highest value is typically interpreted as the predicted class, so the network does not have the option to reject a sample that fits neither of the five TiO<sub>2</sub> phases.</p> <h2 id="references">References</h2> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>Wang, H., et al. “Rapid identification of X-ray diffraction patterns based on very limited data by interpretable convolutional neural networks.” Journal of chemical information and modeling 60.4 (2020): 2004-2011. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:2" role="doc-endnote"> <p>Schuetzke, J., et al. “Enhancing deep-learning training for phase identification in powder X-ray diffractograms.” IUCrJ 8.3 (2021): 408-420. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </div> </article> </div> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Jan Schützke. <a href="https://jschuetzke.github.io/impressum/">Impressum</a>.Last updated: March 04, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>