<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://jschuetzke.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jschuetzke.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-13T15:16:13+00:00</updated><id>https://jschuetzke.github.io/feed.xml</id><title type="html">blank</title><subtitle>Accelerating the analysis of diffraction or spectroscopy data. </subtitle><entry><title type="html">Training a neural network for the classification of TiO2 XRD patterns</title><link href="https://jschuetzke.github.io/blog/2024/tio2-classification/" rel="alternate" type="text/html" title="Training a neural network for the classification of TiO2 XRD patterns"/><published>2024-02-26T10:55:00+00:00</published><updated>2024-02-26T10:55:00+00:00</updated><id>https://jschuetzke.github.io/blog/2024/tio2-classification</id><content type="html" xml:base="https://jschuetzke.github.io/blog/2024/tio2-classification/"><![CDATA[<p>This post demonstrates the usage of neural networks for automatic analysis of powder XRD data. In this application, the objective is to identify various TiO<sub>2</sub> structures based on their characteristic pattern.</p> <h2 id="titanium-oxides">Titanium Oxides</h2> <p>Titanium oxide TiO<sub>2</sub> can crystallize in various arrangements, depending on diverse influences. According to crystalline databases, such as the <a href="https://www.crystallography.net/cod/">COD</a> or the <a href="https://icsd.fiz-karlsruhe.de/">ICSD</a>, there are 5 major phases to consider at ambient conditions:</p> <ul> <li>Anatase, e.g., COD 9009086</li> <li>Rutile, e.g., COD 9015662</li> <li>Brookite, e.g., COD 8104269</li> <li>β-TiO<sub>2</sub>, e.g., COD 1528778</li> <li>TiO<sub>2</sub>-II, e.g., COD 1530026</li> </ul> <p>While the chemical composition for all of these phases is identical, their crystalline structures differ. Therefore, the XRD technique is a useful method to determine the exact phase for titanium oxide samples.</p> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/xrd-class-patterns-480.webp 480w, /assets/img/xrd-class-patterns-800.webp 800w, /assets/img/xrd-class-patterns-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/xrd-class-patterns.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The above figure shows the simulated, ideal diffraction patterns for the different structures. While the highest peak lies in the range between 25 and 30 degrees \(2θ\) for 4 of the 5 variants (TiO<sub>2</sub>-II being the exception), the structures are distinguishable based on the presence and positions of additional diffraction peaks. Therefore, it can be expected that an automated classification algorithm is able to classify the structures accordingly.</p> <h2 id="network-training">Network Training</h2> <p>The use of neural networks for analysis of powder XRD patterns has been demonstrated in various publications.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup><sup>,</sup><sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> Nonetheless, exemplary data is necessary to train the network models. This data should demonstrate all types of variations found in the powder XRD patterns, so the model can learn robust classification rules for the different structures. However, measured XRD patterns are not readily available for all types of materials. Thus, simulated XRD patterns are typically utilized as training data. The previous <a href="https://jschuetzke.github.io/blog/2024/realistic-xrd-simulation/">blog post</a> explains the procedure in detail using the <em>python-powder-diffraction</em> package.</p> <h3 id="requirements">Requirements</h3> <ol> <li>A fresh Python environment, e.g., through venv or conda.</li> <li>CIFs for the different TiO<sub>2</sub> variants, e.g., from the COD.</li> <li>The <a href="https://github.com/jschuetzke/python-powder-diffraction/"><em>python-powder-diffraction</em></a> package installed in the environment.</li> <li>A deep learning package, such as <a href="https://tensorflow.org/"><em>TensorFlow</em></a> or <a href="https://pytorch.org/"><em>PyTorch</em></a> installed in the environment.</li> </ol> <h3 id="data-generation">Data Generation</h3> <p>The <em>python-powder-diffraction</em> provides several methods to generate varied patterns for each structure, but the fastest option is the use of the <code class="language-plaintext highlighter-rouge">generate-varied-patterns</code> script provided in the package. Simply place all CIFs in a folder (e.g., in a directory called <em>phases</em>), activate the enviroment and use <code class="language-plaintext highlighter-rouge">generate-varied-patterns phases</code> to generate the signals.</p> <p>Furthermore, there are several arguments to modify the data generation procedure. Here, we’re aiming to simulate patterns in the 5 to 90 degrees \(2θ\) range with step width \(0.01^\circ \Delta 2\theta\). To depict the peak positions, intensities, and shape variations, we also specify values for those parameters:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>generate-varied-patterns phases --theta_range "(5,90)" --strain 0.04 --texture 0.8 --domain_sizes "(20,50)" --n_train 100 --n_val 20
</code></pre></div></div> <p>Executing this script generates four numpy files in the <em>phases</em> directory: <code class="language-plaintext highlighter-rouge">x_train.npy</code>, <code class="language-plaintext highlighter-rouge">x_val.npy</code>, <code class="language-plaintext highlighter-rouge">y_train.npy</code>, and <code class="language-plaintext highlighter-rouge">y_val.npy</code>. The <em>x</em> arrays contain the signals (100 or 20 variants for each CIF) and the <em>y</em> arrays the labels for each pattern. By default, the CIFs are sorted according to their name and given an identifier in ascending order. Therefore, the labels file only contains the numerical identifier that specifies the structure for each signal in the <em>train</em> and <em>val</em> files.</p> <p>Furthermore, the artificial signals should also contain background and noise. This can be added using the <code class="language-plaintext highlighter-rouge">add-noise</code> script. Noise can either be added to each signals array separately or in a single script execution using the <code class="language-plaintext highlighter-rouge">--template</code> argument. To add noise in a single call, we change the directory to the <em>phases</em> folder and call the script as follows:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>add-noise --template "x_" --noise_min 0.01 --noise_max 0.05
</code></pre></div></div> <p>This call adds random background and noise to the <code class="language-plaintext highlighter-rouge">x_train.npy</code> and <code class="language-plaintext highlighter-rouge">x_val.npy</code> files and saves the modified arrays as <code class="language-plaintext highlighter-rouge">x_train_noise.npy</code> and <code class="language-plaintext highlighter-rouge">x_val_noise.npy</code>. The resulting signals appear as follows:</p> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/xrd-class-signals-480.webp 480w, /assets/img/xrd-class-signals-800.webp 800w, /assets/img/xrd-class-signals-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/xrd-class-signals.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="neural-network">Neural Network</h3> <p>Convolutional neural networks employ various filters that are shifted across the input to identify features in the signals. Therefore, this architecture is well suited to distinguish the relevant peak-encoded information from background and noise. Here, we use a simple network consisting of three convolutional layers. Each generated signal corresponds to one of the unique structures, which represents a multi-class task. Therefore, the output of the network has five neurons and the outputs are scaled using the <em>softmax</em> activation function, to represent the predicted values as a probability distribution.</p> <p>The neural network model, in this example using the keras implementation with a tensorflow backend, can be defined as follows:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">metrics</span>

<span class="k">def</span> <span class="nf">get_cnn</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">8501</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">input_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
                               <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">input</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span>
                      <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">input_layer</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">MaxPool1D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span>
                      <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">MaxPool1D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span>
                      <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">MaxPool1D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">flat</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="sh">"</span><span class="s">adam</span><span class="sh">"</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">sparse_categorical_crossentropy</span><span class="sh">'</span><span class="p">,</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">metrics</span><span class="p">.</span><span class="nc">SparseCategoricalAccuracy</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></div> <p>This implements a model with 8501 input neurons and 5 neurons in the output layer. Three convolutional layers with 16 filters each (and kernel sizes 35, 25, and 15) are employed within the network, together with pooling operations to reduce the dimensionality of the signals. The label files <code class="language-plaintext highlighter-rouge">y_train.npy</code> and <code class="language-plaintext highlighter-rouge">y_val.npy</code> specify the identifiers of each class, so the <em>sparse_categorical_crossentropy</em> loss (and accuracy object) is used. Furthermore, the <em>Adam</em> optimizer is used during model training.</p> <h3 id="training-procedure">Training Procedure</h3> <p>The next step involves the training of the neural network using the simulated patterns. Therefore, the first steps of the training script involve loading the signals.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">tensorflow.keras</span> <span class="kn">import</span> <span class="n">callbacks</span>
<span class="kn">from</span> <span class="n">powdiffrac.processing</span> <span class="kn">import</span> <span class="n">scale_min_max</span>
<span class="kn">from</span> <span class="n">model</span> <span class="kn">import</span> <span class="n">get_cnn</span>


<span class="n">xt</span> <span class="o">=</span> <span class="nf">scale_min_max</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">./phases/x_train.npy</span><span class="sh">"</span><span class="p">))</span>
<span class="n">xv</span> <span class="o">=</span> <span class="nf">scale_min_max</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">./phases/x_val.npy</span><span class="sh">"</span><span class="p">))</span>
<span class="n">yt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">./phases/y_train.npy</span><span class="sh">"</span><span class="p">)</span>
<span class="n">yv</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">./phases/y_val.npy</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>Following this, the model can get initiliazed based on the properties of the training data. Consisting of 5 unique classes, adapting the model to the training data requires only few epochs.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="nf">get_cnn</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">xv</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">classes</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">yv</span><span class="p">).</span><span class="n">size</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">xv</span><span class="p">,</span> <span class="n">yv</span><span class="p">),</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">./phases/model.keras</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>In my configuration (GTX 1070), the model achieves 100% accuracy on training and validation set. This is especially remarkable because the model has never seen the varied patterns in the validation data.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 10/10
16/16 - 0s - loss: 1.3780e-07 - accuracy: 1.0000 - val_loss: 4.3869e-07 - val_accuracy: 1.0000 - 209ms/epoch - 13ms/step
</code></pre></div></div> <h2 id="network-application">Network Application</h2> <p>While the model has been trained and evaluated on simulated patterns, it is also readily applicable for the classification of measured powder XRD patterns. Therefore, the following section demonstrates the performance of the neural network model on measured signals.</p> <h3 id="rruff-measurements">RRUFF Measurements</h3> <p>The <a href="https://rruff.info">RRUFF</a> database provides measured XRD patterns and Raman spectra for various materials. This database includes entries for some of the TiO<sub>2</sub> variants, enabling an effective evaluation of the trained neural network model using measured signals. The database includes the following entries:</p> <table> <thead> <tr> <th>Phase</th> <th style="text-align: right">Entries</th> <th style="text-align: right">…</th> <th style="text-align: right">…</th> <th style="text-align: right">…</th> </tr> </thead> <tbody> <tr> <td>Anatase</td> <td style="text-align: right">R060277</td> <td style="text-align: right">R070582</td> <td style="text-align: right">R120013</td> <td style="text-align: right">R120064</td> </tr> <tr> <td>Rutile</td> <td style="text-align: right">R040049</td> <td style="text-align: right">R050031</td> <td style="text-align: right">R050417</td> <td style="text-align: right">R060493</td> </tr> <tr> <td>Brookite</td> <td style="text-align: right">R050363</td> <td style="text-align: right">R050591</td> <td style="text-align: right">R130225</td> <td style="text-align: right"> </td> </tr> </tbody> </table> <p>Unfortunately, the entries for the four Anatase samples do not contain measured XRD patterns and the database only provides simulated signals. Nonetheless, the process to generate those simulated patterns presumably differs from the approach to generate the training signals, so this is another useful tool to test the robustness of the automated analysis approach.</p> <h3 id="prediction">Prediction</h3> <p>The measured patterns are available for download from the RRUFF, enabling the evaluation of the trained model in a Python script. Accordingly, the scans are imported into Python (using numpy functions) and Min-Max-scaled prior to feeding the signals into the network. The order of the signals corresponds to the table above, meaning that signals 1-4 represent anatase, signals 5-8 represent rutile, and the remaining depict brookite.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="sh">"</span><span class="s">./phases/model.keras</span><span class="sh">"</span><span class="p">)</span>
<span class="n">anatase_1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="sh">'</span><span class="s">./meas/Anatase__R060277-9__Powder__Xray_Data_XY_RAW__5487.txt</span><span class="sh">'</span><span class="p">,</span> <span class="n">comments</span><span class="o">=</span><span class="sh">'</span><span class="s">#</span><span class="sh">'</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="p">)</span>
<span class="bp">...</span>
<span class="n">meas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="mi">11</span><span class="p">,</span><span class="mi">8501</span><span class="p">])</span>
<span class="n">meas</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">interp</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mf">5.</span><span class="p">,</span><span class="mf">90.</span><span class="p">,</span><span class="mi">8501</span><span class="p">),</span> <span class="n">anatase_1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">anatase_1</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="bp">...</span>
<span class="n">meas</span> <span class="o">=</span> <span class="nf">scale_min_max</span><span class="p">(</span><span class="n">meas</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">meas</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 2])
</code></pre></div></div> <p>The network provides the correct predictions for the measured signals (identifiers-&gt; 1: Anatase, 2: β-TiO<sub>2</sub>, 2: Brookite, 3: Rutile, 4: TiO<sub>2</sub>-II), corresponding to an accuracy score of 100%.</p> <h3 id="limitations">Limitations</h3> <p>While the network demonstrates proficiency in classifying XRD patterns of titanium oxide samples, there are several other cases that can occur when analyzing a crystalline sample. For once, the sample could contain several phases, such as impurities. Secondly, the sample could contain neither of the defined phases. The network presented here is not trained to handle either of these exceptional cases. Accordingly, the network classified the first rutile sample from the RRUFF (R040049) as rutile, despite the presence of hematite in the sample (as indicated in the RRUFF entry). Due to the use of the <em>softmax</em> activation function in the final layer, the output with the highest value is typically interpreted as the predicted class, so the network does not have the option to reject a sample that fits neither of the five TiO<sub>2</sub> phases.</p> <h2 id="references">References</h2> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>Wang, H., et al. “Rapid identification of X-ray diffraction patterns based on very limited data by interpretable convolutional neural networks.” Journal of chemical information and modeling 60.4 (2020): 2004-2011. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2" role="doc-endnote"> <p>Schuetzke, J., et al. “Enhancing deep-learning training for phase identification in powder X-ray diffractograms.” IUCrJ 8.3 (2021): 408-420. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="guides"/><category term="python"/><category term="xrd"/><category term="classification"/><summary type="html"><![CDATA[A guide to instruct and demonstrate how neural networks can be employed for automatic phase identification in powder XRD patterns.]]></summary></entry><entry><title type="html">Simulation of realistic powder X-ray diffraction patterns</title><link href="https://jschuetzke.github.io/blog/2024/realistic-xrd-simulation/" rel="alternate" type="text/html" title="Simulation of realistic powder X-ray diffraction patterns"/><published>2024-02-23T09:05:00+00:00</published><updated>2024-02-23T09:05:00+00:00</updated><id>https://jschuetzke.github.io/blog/2024/realistic-xrd-simulation</id><content type="html" xml:base="https://jschuetzke.github.io/blog/2024/realistic-xrd-simulation/"><![CDATA[<p>This post shows how to utilize the python-powder-diffraction package to simulate realistic powder XRD patterns.</p> <h2 id="powder-xrd-patterns">Powder XRD patterns</h2> <p>X-ray diffraction (XRD) is a popular method to analyze crystalline sampes. In practice, the sample is often ground into a fine powder to analyze the sample from all directions simultaneously without the need to rotate the sample. Thus, the data is recorded as pairs of angles (typically \(2θ\)) and corresponding intensities. These diffraction patterns provide valuable information about the crystal structure, including lattice spacing and symmetry. Furthermore, the pattern contains information regarding the specimen, such as the size of grains in the powder.</p> <p>Depending on the chemical composition and arrangement within the resulting crystal structure, each material exhibits a unique diffraction pattern characterized by specific peak intensities and positions. As a result, the diffraction pattern serves as a distinctive fingerprint that can be used to identify materials present in the recorded data. By comparing experimental diffraction patterns with known reference patterns stored in databases, scientists can accurately determine the composition and structure of the crystalline sample under investigation. Therefore, XRD is widely employed in various domains to rapidly identify known materials and ensure quality control, while also playing a crucial role in research to determine the properties of novel materials.</p> <h3 id="appearance">Appearance</h3> <p>The following figure shows an exemplary XRD pattern that has been acquired from the <a href="https://rruff.info/">RRUFF database</a>. In particular, entry R050031 has been selected, which corresponds to the mineral rutile. This substance with chemical composition TiO<sub>2</sub> and a tetragonal crystal structure has been analyzed using a XRD instrument with a copper anode (wavelength 0.1540562 nm), resulting in the following pattern:</p> <div class="l-page"> <iframe src="/assets/plotly/rutile_R050031.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe> </div> <p>The signal displays multiple peaks (e.g., at positions 27, 36, and 54 degrees \(2θ\)), each exhibiting a broad shape. Additionally, the signal exhibits noise and artifacts, such as the bump observed at the beginning of the measurement, which do not correspond to the characteristic diffraction pattern of the rutile sample. These discrepancies may be attributed to various factors collectively referred to as “background”. The analysis of the acquired diffraction pattern enabled the determination of lattice parameters, as reported: \(a = b = 4.5945; c = 2.9594\).</p> <h3 id="reported-information">Reported Information</h3> <p>While the RRUFF database offers measured XRD patterns for certain minerals, the data extracted from these diffraction patterns is generally stored in a condensed format. Databases like the <a href="https://www.crystallography.net/cod/">COD</a> or the <a href="https://icsd.fiz-karlsruhe.de/">ICSD</a> have thousands of entries, containing comprehensive information on chemical composition and crystal structure arrangement. These databases also offer the option to download the structural information, often in the form of <em>crystallographic information files</em> (<a href="https://www.iucr.org/resources/cif/documentation">CIFs</a>), which allows researchers to utilize the data for subsequent analysis and simulations.</p> <hr/> <h2 id="pattern-simulation">Pattern Simulation</h2> <p>Utilizing the condensed information, calculating the corresponding positions and intensities of diffraction peaks for a given structure becomes a straightforward process. Therefore, this method has been incorporated into numerous software packages, including those designed for the Search/Match procedure and various scientific applications. For the purposes of this post, the implementation provided by <a href="https://pymatgen.org/"><em>pymatgen</em></a> is utilized, though alternative options such as <a href="https://cctbx.github.io/"><em>cctbx</em></a> are also available. An overview of commercial and free-to-use Search/Match software is given <a href="http://www.ccp14.ac.uk/solution/search-match.htm">here</a>.</p> <h3 id="requirements">Requirements</h3> <p>In order to utilize the Python package <em>pymatgen</em>, several prerequisites are required:</p> <ol> <li>A fresh Python environment, e.g., through venv or conda.</li> <li>The installation of pymatgen and required packages through <code class="language-plaintext highlighter-rouge">pip install pymatgen</code>.</li> <li>A CIF of the structure to simulate, here a rutile structure from the COD <a href="http://www.crystallography.net/cod/9015662.html">9015662</a>.</li> </ol> <h3 id="procedure">Procedure</h3> <p>First, read the CIF. The <em>pymatgen</em> modules interpret this information and represent it as follows:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pymatgen.core</span> <span class="kn">import</span> <span class="n">Structure</span>
<span class="n">struct</span> <span class="o">=</span> <span class="n">Structure</span><span class="p">.</span><span class="nf">from_file</span><span class="p">(</span><span class="sh">'</span><span class="s">Downloads/9015662.cif</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">struct</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Structure Summary
Lattice
    abc : 4.5937 4.5937 2.9587
 angles : 90.0 90.0 90.0
 volume : 62.434723178803
      A : 4.5937 0.0 2.8128300006215983e-16
      B : 7.387233015819564e-16 4.5937 2.8128300006215983e-16
      C : 0.0 0.0 2.9587
    pbc : True True True
PeriodicSite: Ti (0.0000, 0.0000, 0.0000) [0.0000, 0.0000, 0.0000]
PeriodicSite: Ti (2.2969, 2.2969, 1.4794) [0.5000, 0.5000, 0.5000]
PeriodicSite: O (1.4001, 1.4001, 0.0000) [0.3048, 0.3048, 0.0000]
PeriodicSite: O (3.1936, 3.1936, 0.0000) [0.6952, 0.6952, 0.0000]
PeriodicSite: O (3.6969, 0.8968, 1.4794) [0.8048, 0.1952, 0.5000]
PeriodicSite: O (0.8968, 3.6969, 1.4794) [0.1952, 0.8048, 0.5000]
</code></pre></div></div> <p>This demonstrates that the dimensions and arrangement of the crystal structure have been processed, as the Structure instance does not include every single Ti and O site in the unit cell. Instead, the remaining positions are represented using the PeriodicSite object. Furthermore, this shows that the lattice dimensions of the rutile structure from the COD differ slightly from the RRUFF entry.</p> <p>To calculate the diffraction pattern information, <em>pymatgen</em> provides the XRDCalculator module, which computes the positions and intensities (scaled according to the highest peak) for a given structure as follows:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pymatgen.analysis.diffraction.xrd</span> <span class="kn">import</span> <span class="n">XRDCalculator</span>
<span class="n">calc</span> <span class="o">=</span> <span class="nc">XRDCalculator</span><span class="p">(</span><span class="n">wavelength</span><span class="o">=</span><span class="sh">"</span><span class="s">CuKa</span><span class="sh">"</span><span class="p">)</span>
<span class="n">pattern</span> <span class="o">=</span> <span class="n">calc</span><span class="p">.</span><span class="nf">get_pattern</span><span class="p">(</span><span class="n">struct</span><span class="p">,</span> <span class="n">two_theta_range</span><span class="o">=</span><span class="p">(</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">90.</span><span class="p">))</span>
</code></pre></div></div> <p>The pattern object contains the discrete peak positions (<code class="language-plaintext highlighter-rouge">pattern.x</code>) and peak intensities (<code class="language-plaintext highlighter-rouge">pattern.y</code>).</p> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/xrd-sim-discrete-480.webp 480w, /assets/img/xrd-sim-discrete-800.webp 800w, /assets/img/xrd-sim-discrete-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/xrd-sim-discrete.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>A visual comparison between the simulated data and the measured XRD pattern validates that the peak positions align. However, notable disparities arise in the intensities: while the highest peak in the measured signal registers at approximately 800 arb. u., the simulated peaks are scaled relative to the highest peak at 100 arb. u. The measured intensities are influenced by various factors, such as instrument configuration and acquisition time. As a result, XRD patterns are commonly analyzed based on the relative intensities captured in the signal. A straightforward method to align the scales of measured and simulated intensities involves scaling based on the minimum and maximum values in each scan, known as Min-Max-Scaling.</p> <p>Furthermore, while the measured peaks exhibit broad shapes, the <em>XRDCalculator</em> module computes only discrete positions. Consequently, additional steps are necessary to modify the calculated diffraction peaks to match the broadened nature of the measured signal. This can be achieved by convolving the peaks with a kernel that approximates a probability distribution (centered at 0). In practice, peak shapes commonly display a Voigt profile. Alternatively, convolution with a Gaussian profile is also feasible and computationally less demanding.</p> <p>Prior to the convolution, it is essential to map the discrete peak positions onto a signal with a defined scanning range and equidistant measurement steps. The measured XRD pattern was obtained within a scanning range spanning from 5 to 90 degrees \(2θ\), with a step width of 0.01 degrees \(\Delta2θ\). Therefore, the calculated peaks are aligned with these measurement steps accordingly.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span> <span class="c1"># represent the simulated signal as a numpy vector
</span>
<span class="c1"># measurement steps
</span><span class="n">steps</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">90.</span><span class="p">,</span> <span class="mi">8501</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># initiliaze signal with all values equal to zero
</span><span class="n">signal</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>

<span class="n">angles</span><span class="p">,</span> <span class="n">intensities</span> <span class="o">=</span> <span class="n">pattern</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">pattern</span><span class="p">.</span><span class="n">y</span>

<span class="c1"># iterate over the computed angles
</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ang</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">angles</span><span class="p">):</span>
    <span class="c1"># determine index of measured step for mapping
</span>    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmin</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">ang</span> <span class="o">-</span> <span class="n">steps</span><span class="p">))</span>
    <span class="c1"># place peak with corresponding intensity in signal
</span>    <span class="n">signal</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">intensities</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="kn">from</span> <span class="n">scipy.ndimage</span> <span class="kn">import</span> <span class="n">gaussian_filter1d</span>

<span class="n">signal</span> <span class="o">=</span> <span class="nf">gaussian_filter1d</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="sh">"</span><span class="s">constant</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/xrd-sim-convolved-480.webp 480w, /assets/img/xrd-sim-convolved-800.webp 800w, /assets/img/xrd-sim-convolved-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/xrd-sim-convolved.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>What is missing now? Mostly the noise and background intensities found in measured signals. In most Search/Match applications, background is modeled through Chebyshev polynomials and noise can be added through random sampling of values from a normal distribution (white noise). Both procedures are straightforward to accomplish in Python:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">coefs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span> <span class="c1"># coefficients for Chebyshev polynomial
</span><span class="n">chebyshev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">polynomial</span><span class="p">.</span><span class="n">chebyshev</span><span class="p">.</span><span class="nc">Chebyshev</span><span class="p">(</span><span class="n">ccoefs</span><span class="p">)</span>
<span class="c1"># evaluate the polynomial according to the measurement steps
</span><span class="n">background</span> <span class="o">=</span> <span class="n">chebyshev</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">steps</span><span class="p">.</span><span class="n">size</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># set seed for reproducability
</span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">default_rng</span><span class="p">(</span><span class="mi">2024</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">rng</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.033</span><span class="p">,</span> <span class="n">steps</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>

<span class="c1"># add to signal, background not needed here
</span><span class="n">signal</span> <span class="o">+=</span> <span class="n">noise</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/xrd-sim-noise-480.webp 480w, /assets/img/xrd-sim-noise-800.webp 800w, /assets/img/xrd-sim-noise-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/xrd-sim-noise.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="python-powder-diffraction">Python-Powder-Diffraction</h2> <h3 id="exemplary-use">Exemplary Use</h3> <p>Instead of manually implementing the code described above, an artificial diffraction pattern can also be generated using the <a href="https://github.com/jschuetzke/python-powder-diffraction/"><em>python-powder-diffraction</em></a> package:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">powdiffrac</span> <span class="kn">import</span> <span class="n">Powder</span>
<span class="kn">from</span> <span class="n">powdiffrac.simulation</span> <span class="kn">import</span> <span class="n">generate_noise</span>
<span class="n">powder</span> <span class="o">=</span> <span class="n">Powder</span><span class="p">.</span><span class="nf">from_cif</span><span class="p">(</span><span class="sh">'</span><span class="s">Downloads/9015662.cif</span><span class="sh">'</span><span class="p">)</span>
<span class="n">signal</span> <span class="o">=</span> <span class="n">powder</span><span class="p">.</span><span class="nf">get_signal</span><span class="p">()</span>
<span class="n">signal</span> <span class="o">=</span> <span class="nf">generate_noise</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>
</code></pre></div></div> <h3 id="pattern-variation">Pattern Variation</h3> <p>Although the generated XRD pattern looks visually similar to the measured signal, minor disparities persist. Firstly, there are slight deviations in peak positions attributable to a mismatch in lattice parameters. Secondly, certain simulated intensity peaks exceed the intensities observed in the measured data. Thirdly, disparities are evident in the shapes of peaks. Nonetheless, such deviations have to be expected in measured diffraction patterns.</p> <p>The <em>Powder</em> object furthermore includes functionality to generate varied signals. For example, the following code generates a pattern with varied peak positions, intensities, and shapes.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">powder</span> <span class="o">=</span> <span class="n">Powder</span><span class="p">.</span><span class="nf">from_cif</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">Downloads/9015662.cif</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">two_theta</span> <span class="o">=</span> <span class="p">(</span><span class="mf">5.</span><span class="p">,</span><span class="mf">90.</span><span class="p">),</span>
    <span class="n">max_strain</span> <span class="o">=</span> <span class="mf">0.04</span><span class="p">,</span> <span class="c1"># position variation
</span>    <span class="n">max_texture</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span> <span class="c1"># intensity variation
</span>    <span class="n">min_domain_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="c1"># minimum grain size 10nm
</span>    <span class="n">max_domain_size</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="c1"># maximum grain size 100nm
</span>    <span class="n">peak_shape</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">lorentzian</span><span class="sh">"</span><span class="p">,</span> <span class="c1"># desired peak shapes
</span>    <span class="n">vary_strain</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
    <span class="n">vary_texture</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
    <span class="n">vary_domain</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="mi">2024</span>
<span class="p">)</span>
<span class="n">signal</span> <span class="o">=</span> <span class="n">powder</span><span class="p">.</span><span class="nf">get_signal</span><span class="p">(</span><span class="n">vary</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">signal</span> <span class="o">=</span> <span class="nf">generate_noise</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/xrd-sim-varied-480.webp 480w, /assets/img/xrd-sim-varied-800.webp 800w, /assets/img/xrd-sim-varied-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/xrd-sim-varied.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure>]]></content><author><name></name></author><category term="guides"/><category term="python"/><category term="xrd"/><category term="simulation"/><summary type="html"><![CDATA[A quick guide to explain the python-powder-diffraction package]]></summary></entry></feed>